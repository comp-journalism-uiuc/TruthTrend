{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "source": [
    "#news stuff\r\n",
    "import newspaper\r\n",
    "from newsapi import NewsApiClient\r\n",
    "\r\n",
    "from datetime import date\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "#cluster stuff\r\n",
    "from sklearn.cluster import DBSCAN\r\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\r\n",
    "\r\n",
    "#nlp stuff\r\n",
    "import spacy\r\n",
    "nlp = spacy.load('en_core_web_lg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "api_key = 'eeeaefaae3c14737bc08e252a6e1991b'\r\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "source": [
    "def get_trending_articles_today(num_trends):\r\n",
    "    today = date.today().strftime(\"%Y-%m-%d\")\r\n",
    "\r\n",
    "    trending_topics = newspaper.hot()\r\n",
    "    if num_trends < len(trending_topics):\r\n",
    "        trending_topics = trending_topics[:num_trends]\r\n",
    "\r\n",
    "    data = []\r\n",
    "    for topic in trending_topics:\r\n",
    "        articles = []\r\n",
    "        for i in range(1, 5):\r\n",
    "            page_articles = newsapi.get_everything(q=topic,\r\n",
    "                                      language='en',\r\n",
    "                                      from_param=today,\r\n",
    "                                      page=i)\r\n",
    "\r\n",
    "            if len(page_articles) == 0:\r\n",
    "                break\r\n",
    "            else:\r\n",
    "                articles.extend(page_articles[\"articles\"])\r\n",
    "\r\n",
    "        # add article info\r\n",
    "        article_info = [(article['publishedAt'], article['title'], article['url'], topic) for article in articles]\r\n",
    "        data.extend(article_info)\r\n",
    "    \r\n",
    "    return pd.DataFrame(data, columns=[\"date\", \"title\", \"url\", \"topic\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "def preprocess_text(text):\r\n",
    "    doc = nlp(text)\r\n",
    "    tokens = [w.lower_ for w in doc if not (w.is_stop or w.is_punct)]\r\n",
    "    preproc_text = \" \".join(tokens) \r\n",
    "    return preproc_text "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "source": [
    "def cluster_articles(df, eps):\r\n",
    "    sent_vecs = {}\r\n",
    "    for title in df.title:\r\n",
    "        try:\r\n",
    "            doc = nlp(preprocess_text(title))\r\n",
    "            sent_vecs.update({title: doc.vector})\r\n",
    "        except Exception as e:\r\n",
    "            print(e)\r\n",
    "\r\n",
    "    vectors = list(sent_vecs.values())\r\n",
    "    titles = list(sent_vecs.keys())\r\n",
    "\r\n",
    "    # create clusters out of news titles\r\n",
    "    x = np.array(vectors)\r\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=2, metric='cosine').fit(x)\r\n",
    "    clusters = pd.DataFrame({'label': dbscan.labels_, 'title': titles, 'vectors': vectors})\r\n",
    "\r\n",
    "    return clusters"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "source": [
    "def get_mean_vec(vectors):\r\n",
    "    total = np.zeros(300)\r\n",
    "    for vec in vectors:\r\n",
    "        total += vec\r\n",
    "\r\n",
    "    mean = total / len(vectors)\r\n",
    "    return mean\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "source": [
    "def get_central_vec_title(cluster):\r\n",
    "    vectors = cluster.vectors.to_list()\r\n",
    "\r\n",
    "    mean_vec = get_mean_vec(vectors)\r\n",
    "    index = pairwise_distances_argmin_min(np.array([mean_vec]), vectors)[0][0]\r\n",
    "    \r\n",
    "    return cluster.title.iloc[index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "source": [
    "def get_categorized_news(clusters, article_df):\r\n",
    "    summarized_news = []\r\n",
    "    for cluster in clusters.label.unique():\r\n",
    "        #unclustered category\r\n",
    "        if cluster == -1:\r\n",
    "            continue\r\n",
    "        \r\n",
    "        # get best article from cluster\r\n",
    "        cluster_titles = clusters.loc[clusters.label == cluster]\r\n",
    "        best_article = get_central_vec_title(cluster_titles)\r\n",
    "\r\n",
    "        #look up in original df\r\n",
    "        cluster_df = article_df.loc[article_df.title == best_article].copy()\r\n",
    "        #label the cluster it's part of\r\n",
    "        cluster_df[\"cluster\"] = cluster\r\n",
    "\r\n",
    "        summarized_news.append(cluster_df)\r\n",
    "\r\n",
    "    return pd.concat(summarized_news)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "source": [
    "trending_news = get_trending_articles_today(6)\r\n",
    "trending_news = trending_news.drop_duplicates(subset=['title'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "source": [
    "clusters = cluster_articles(trending_news, .12)\r\n",
    "summarized_news = get_categorized_news(clusters, trending_news)\r\n",
    "summarized_news"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "bdb1f293a72cda3337025d9d00554afb1343cd7218118617db03a8cb5103ebd2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}