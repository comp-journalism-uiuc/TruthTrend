{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "import newspaper\r\n",
    "from newsapi import NewsApiClient\r\n",
    "from datetime import date\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.cluster import DBSCAN\r\n",
    "\r\n",
    "import spacy\r\n",
    "nlp = spacy.load('en_core_web_lg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "api_key = 'eeeaefaae3c14737bc08e252a6e1991b'\r\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "def get_trending_articles_today():\r\n",
    "    today = date.today().strftime(\"%Y-%m-%d\")\r\n",
    "    trending_topics = newspaper.hot()[:5]\r\n",
    "\r\n",
    "    data = []\r\n",
    "    for topic in trending_topics:\r\n",
    "        articles = []\r\n",
    "        for i in range(1, 5):\r\n",
    "            page_articles = newsapi.get_everything(q=topic,\r\n",
    "                                      language='en',\r\n",
    "                                      from_param=today,\r\n",
    "                                      page=i)\r\n",
    "\r\n",
    "            if len(page_articles) == 0:\r\n",
    "                break\r\n",
    "            else:\r\n",
    "                articles.extend(page_articles[\"articles\"])\r\n",
    "\r\n",
    "        # add article info\r\n",
    "        article_info = [(article['publishedAt'], article['title'], article['url'], topic) for article in articles]\r\n",
    "        data.extend(article_info)\r\n",
    "    \r\n",
    "    return pd.DataFrame(data, columns=[\"date\", \"title\", \"url\", \"topic\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "source": [
    "df = get_trending_articles_today()\r\n",
    "df = df.drop_duplicates(subset=['title'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "sent_vecs = {}\r\n",
    "for title in df.loc[df.topic == \"NASCAR\"].title:\r\n",
    "    try:\r\n",
    "        doc = nlp(title)\r\n",
    "        sent_vecs.update({'title': doc.vector})\r\n",
    "    except Exception as e:\r\n",
    "        print(e)\r\n",
    "\r\n",
    "vectors = list(sent_vecs.values())\r\n",
    "x = np.array(vectors)\r\n",
    "dbscan = DBSCAN(eps=100, min_samples=2, metric='cosine').fit(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "dbscan.labels_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 206
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "bdb1f293a72cda3337025d9d00554afb1343cd7218118617db03a8cb5103ebd2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}