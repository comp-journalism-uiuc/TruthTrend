{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 380,
   "source": [
    "#news stuff\r\n",
    "import newspaper\r\n",
    "from newsapi import NewsApiClient\r\n",
    "\r\n",
    "from datetime import date\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "#cluster stuff\r\n",
    "from sklearn.cluster import DBSCAN\r\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\r\n",
    "\r\n",
    "#nlp stuff\r\n",
    "import spacy\r\n",
    "nlp = spacy.load('en_core_web_lg')\r\n",
    "\r\n",
    "#summarization\r\n",
    "from rake_nltk import Rake\r\n",
    "rake_nltk_var = Rake()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "source": [
    "api_key = 'eeeaefaae3c14737bc08e252a6e1991b'\r\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "source": [
    "def get_trending_articles_today(num_trends):\r\n",
    "    today = date.today().strftime(\"%Y-%m-%d\")\r\n",
    "\r\n",
    "    trending_topics = newspaper.hot()\r\n",
    "    if num_trends < len(trending_topics):\r\n",
    "        trending_topics = trending_topics[:num_trends]\r\n",
    "\r\n",
    "    data = []\r\n",
    "    for topic in trending_topics:\r\n",
    "        articles = []\r\n",
    "        for i in range(1, 5):\r\n",
    "            page_articles = newsapi.get_everything(q=topic,\r\n",
    "                                      language='en',\r\n",
    "                                      from_param=today,\r\n",
    "                                      page=i)\r\n",
    "\r\n",
    "            if len(page_articles) == 0:\r\n",
    "                break\r\n",
    "            else:\r\n",
    "                articles.extend(page_articles[\"articles\"])\r\n",
    "\r\n",
    "        # add article info\r\n",
    "        article_info = [(article['publishedAt'], article['title'], article['url'], topic) for article in articles]\r\n",
    "        data.extend(article_info)\r\n",
    "    \r\n",
    "    return pd.DataFrame(data, columns=[\"date\", \"title\", \"url\", \"topic\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "source": [
    "def preprocess_text(text):\r\n",
    "    doc = nlp(text)\r\n",
    "    tokens = [w.lower_ for w in doc if not (w.is_stop or w.is_punct)]\r\n",
    "    preproc_text = \" \".join(tokens) \r\n",
    "    return preproc_text "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "source": [
    "def cluster_articles(df, eps):\r\n",
    "    sent_vecs = {}\r\n",
    "    for title in df.title:\r\n",
    "        try:\r\n",
    "            doc = nlp(preprocess_text(title))\r\n",
    "            sent_vecs.update({title: doc.vector})\r\n",
    "        except Exception as e:\r\n",
    "            print(e)\r\n",
    "\r\n",
    "    vectors = list(sent_vecs.values())\r\n",
    "    titles = list(sent_vecs.keys())\r\n",
    "\r\n",
    "    # create clusters out of news titles\r\n",
    "    x = np.array(vectors)\r\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=2, metric='cosine').fit(x)\r\n",
    "    clusters = pd.DataFrame({'label': dbscan.labels_, 'title': titles, 'vectors': vectors})\r\n",
    "\r\n",
    "    return clusters"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "source": [
    "def get_mean_vec(vectors):\r\n",
    "    total = np.zeros(300)\r\n",
    "    for vec in vectors:\r\n",
    "        total += vec\r\n",
    "\r\n",
    "    mean = total / len(vectors)\r\n",
    "    return mean\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "source": [
    "def get_central_vec_title(cluster):\r\n",
    "    vectors = cluster.vectors.to_list()\r\n",
    "\r\n",
    "    mean_vec = get_mean_vec(vectors)\r\n",
    "    index = pairwise_distances_argmin_min(np.array([mean_vec]), vectors)[0][0]\r\n",
    "    \r\n",
    "    return cluster.title.iloc[index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "source": [
    "def get_categorized_news(clusters, article_df):\r\n",
    "    summarized_news = []\r\n",
    "    for cluster in clusters.label.unique():\r\n",
    "        #unclustered category\r\n",
    "        if cluster == -1:\r\n",
    "            continue\r\n",
    "        \r\n",
    "        # get best article from cluster\r\n",
    "        cluster_titles = clusters.loc[clusters.label == cluster]\r\n",
    "        best_article = get_central_vec_title(cluster_titles)\r\n",
    "\r\n",
    "        #look up in original df\r\n",
    "        cluster_df = article_df.loc[article_df.title == best_article].copy()\r\n",
    "        #label the cluster it's part of\r\n",
    "        cluster_df[\"cluster\"] = cluster\r\n",
    "\r\n",
    "        summarized_news.append(cluster_df)\r\n",
    "\r\n",
    "    return pd.concat(summarized_news)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "source": [
    "def label_cluster(row):\r\n",
    "    document = row.title\r\n",
    "\r\n",
    "    # extract longest keword\r\n",
    "    rake_nltk_var.extract_keywords_from_text(document)\r\n",
    "    keyword_extracted = rake_nltk_var.get_ranked_phrases()\r\n",
    "    title = max(keyword_extracted, key=len)\r\n",
    "\r\n",
    "    return title"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "source": [
    "trending_news = get_trending_articles_today(6)\r\n",
    "trending_news = trending_news.drop_duplicates(subset=['title'])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NewsAPIException",
     "evalue": "{'status': 'error', 'code': 'rateLimited', 'message': 'You have made too many requests recently. Developer accounts are limited to 100 requests over a 24 hour period (50 requests available every 12 hours). Please upgrade to a paid plan if you need more requests.'}",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNewsAPIException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-416-b9b72694eb31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrending_news\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_trending_articles_today\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrending_news\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrending_news\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-371-efb52f72f1e6>\u001b[0m in \u001b[0;36mget_trending_articles_today\u001b[1;34m(num_trends)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0marticles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             page_articles = newsapi.get_everything(q=topic,\n\u001b[0m\u001b[0;32m     13\u001b[0m                                       \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                       \u001b[0mfrom_param\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\newsapi\\newsapi_client.py\u001b[0m in \u001b[0;36mget_everything\u001b[1;34m(self, q, qintitle, sources, domains, exclude_domains, from_param, to, language, sort_by, page, page_size)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Check Status of Request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNewsAPIException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewsAPIException\u001b[0m: {'status': 'error', 'code': 'rateLimited', 'message': 'You have made too many requests recently. Developer accounts are limited to 100 requests over a 24 hour period (50 requests available every 12 hours). Please upgrade to a paid plan if you need more requests.'}"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "source": [
    "# put all trending news into clusters and pick most objective article for each one\r\n",
    "clusters = cluster_articles(trending_news, .12)\r\n",
    "summarized_news = get_categorized_news(clusters, trending_news)\r\n",
    "\r\n",
    "# summarize each cluster\r\n",
    "summarized_news = summarized_news.reset_index(drop=True)\r\n",
    "summarized_news[\"cluster_title\"] = summarized_news.apply(label_cluster, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "bdb1f293a72cda3337025d9d00554afb1343cd7218118617db03a8cb5103ebd2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}